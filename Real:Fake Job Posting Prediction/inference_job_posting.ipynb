{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-16 16:00:02.988096: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as tf_hub\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# import preprocessing\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the embedding layer\n",
    "url = 'https://tfhub.dev/google/tf2-preview/nnlm-en-dim128-with-normalization/1'\n",
    "hub_layer = tf_hub.KerasLayer(url, output_shape=[128], input_shape=[], dtype=tf.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "model_nlp = load_model('improve_model_lstm.keras',custom_objects={'KerasLayer': hub_layer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for text removal\n",
    "def text_removal(text):\n",
    "    '''\n",
    "    Function to automate the deletion of unnecessary text.\n",
    "    '''\n",
    "    # convert text to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # hashtags removal\n",
    "    text = re.sub(r\"#\\w+\", \" \", text)\n",
    "\n",
    "    # newline removal (\\n)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "\n",
    "    # URL removal\n",
    "    text = re.sub(r\"http\\S+\", \" \", text)\n",
    "    text = re.sub(r\"www\\S+\", \" \", text)\n",
    "\n",
    "    # symbol '&' removal\n",
    "    text = re.sub(r\"&amp;\", \" \", text) #in HTML\n",
    "\n",
    "    # punctuation removal\n",
    "    text = re.sub(r\"[^\\w\\s]\", \" \", text)\n",
    "\n",
    "    # non-letter removal (such as emoticon, symbol (like μ, $, 兀), etc\n",
    "    text = re.sub(r\"[^A-Za-z\\s']\", \" \", text)\n",
    "\n",
    "    # multiple spaces removal\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # whitespace removal\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for stopwords removal\n",
    "def stopwords_removal(text):\n",
    "    '''\n",
    "    Function to automate the removal of stopwords ('and','or') and custom stopwords using the NLTK library.\n",
    "    '''\n",
    "    # defining stopwords\n",
    "    stpwrd_eng = set(stopwords.words('english'))\n",
    "    custom_stopwords = ['job','jobs','position','positions','career','careers']\n",
    "    stpwrd_eng.update(custom_stopwords)\n",
    "\n",
    "    # tokenization\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # stopwords removal\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stpwrd_eng]\n",
    "\n",
    "    # joining stopwords tokens back into a string\n",
    "    cleaned_text = ' '.join(filtered_tokens)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function for lemmatization\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    Function to soften text by returning a word to its base (lemmatization) using the NLTK library.\n",
    "    '''\n",
    "    # defining lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # tokenization\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # lemmatization\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "    # joining lemmatized tokens back into a string\n",
    "    lemmatized_text = ' '.join(lemmatized_tokens)\n",
    "\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining tokens from preprocess\n",
    "def text_preprocessing(text):\n",
    "    '''\n",
    "    Function to combine the results of text removal, stopwords removal, and lemmatization.\n",
    "    '''\n",
    "    text = text_removal(text)\n",
    "    text = stopwords_removal(text)\n",
    "    text = lemmatization(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n    ABC Corporation is a pioneering leader i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  \\n    ABC Corporation is a pioneering leader i..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new data\n",
    "df_inf = {\n",
    "    'text':\n",
    "    '''\n",
    "    ABC Corporation is a pioneering leader in the healthcare technology sector, dedicated to revolutionizing patient care through innovative solutions. Established in 2005, our company has consistently delivered cutting-edge medical devices and software that elevate healthcare standards worldwide.\n",
    "    ABC Corporation is seeking a dynamic and experienced Business Partnership Manager to expand our strategic alliances and foster growth opportunities. As a Business Partnership Manager, you will be responsible for developing and managing partnerships with key stakeholders, including healthcare providers, technology partners, and strategic alliances.\n",
    "    Bachelor's degree in Business Administration, Marketing, or a related field. MBA preferred. Proven track record of success in business development or partnership management, preferably in the healthcare or technology sector. Strong negotiation and interpersonal skills with the ability to build and maintain relationships at all levels. Strategic thinker with a clear understanding of market dynamics and business trends. Excellent communication and presentation skills.\n",
    "    '''\n",
    "}\n",
    "\n",
    "df_inf = pd.DataFrame([df_inf])\n",
    "df_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n    ABC Corporation is a pioneering leader i...</td>\n",
       "      <td>abc corporation pioneering leader healthcare t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  \\n    ABC Corporation is a pioneering leader i...   \n",
       "\n",
       "                                      text_processed  \n",
       "0  abc corporation pioneering leader healthcare t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying text preprocessing\n",
    "df_inf['text_processed'] = df_inf['text'].apply(lambda x: text_preprocessing(x))\n",
    "df_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "The job posting is real.\n"
     ]
    }
   ],
   "source": [
    "# predict for binary classification\n",
    "predict = model_nlp.predict(df_inf['text_processed'])\n",
    "predict = np.where(predict >= 0.5, 1, 0)\n",
    "predict\n",
    "\n",
    "for i in predict:\n",
    "    if i == 0:\n",
    "        print('The job posting is real.')\n",
    "    else:\n",
    "        print('The job posting is fake.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
